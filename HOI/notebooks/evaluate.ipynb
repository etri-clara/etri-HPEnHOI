{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Tue_May__3_18:49:52_PDT_2022\n",
      "Cuda compilation tools, release 11.7, V11.7.64\n",
      "Build cuda_11.7.r11.7/compiler.31294372_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djjin/anaconda3/envs/conda_X_decoder/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch:  1.13 ; cuda:  cu117\n",
      "detectron2: 0.6\n"
     ]
    }
   ],
   "source": [
    "import torch, detectron2\n",
    "!nvcc --version\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "print(\"detectron2:\", detectron2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/djjin/Mygit/HOI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid MIT-MAGIC-COOKIE-1 key"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import argparse\n",
    "os.environ[\"DATASET\"] = \"../datasets\"\n",
    "\n",
    "pth = '/'.join(sys.path[0].split('/')[:-1])\n",
    "sys.path.insert(0, pth)\n",
    "\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "\n",
    "home_dir = os.path.abspath(os.getcwd()+\"/../\")\n",
    "sys.path.append(home_dir)\n",
    "print(home_dir)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from hdecoder.BaseModel import BaseModel\n",
    "from hdecoder import build_model\n",
    "from utils.distributed import init_distributed\n",
    "from utils.arguments import load_opt_from_config_files, load_config_dict_to_opt\n",
    "from utils.misc import MetricLogger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model path and load config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:utils.arguments:Overrided DONT_LOAD_MODEL from True to False\n"
     ]
    }
   ],
   "source": [
    "from utils.arguments import load_vcoco_opt_command, load_vcoco_parser\n",
    "\n",
    "cmdline_args = load_vcoco_parser()\n",
    "cmdline_args.conf_files = [os.path.join(home_dir, \"configs/hdecoder/vcoco_large.yaml\")]\n",
    "\n",
    "model_path = '../checkpoints/vcoco_hdecoder_l.pt'\n",
    "cmdline_args.overrides = ['DONT_LOAD_MODEL', 'false', 'PYLEARN_MODEL', model_path] \n",
    "\n",
    "opt = load_vcoco_opt_command(cmdline_args)\n",
    "opt = init_distributed(opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Official V-COCO Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt[\"POSTPROCESS\"][\"OFFICIAL\"][\"USE\"] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:trainer.distributed_trainer:Setting SAVE_DIR as data/output_large/test\n",
      "INFO:trainer.distributed_trainer:Using CUDA\n",
      "WARNING:trainer.utils.mpi_adapter:----------------\n",
      "WARNING:trainer.utils.mpi_adapter:MPI Adapter data\n",
      "WARNING:trainer.utils.mpi_adapter:----------------\n",
      "WARNING:trainer.utils.mpi_adapter:environment info: no MPI\n",
      "WARNING:trainer.utils.mpi_adapter:init method url: tcp://127.0.0.1:36873\n",
      "WARNING:trainer.utils.mpi_adapter:world size: 1\n",
      "WARNING:trainer.utils.mpi_adapter:local size: 1\n",
      "WARNING:trainer.utils.mpi_adapter:rank: 0\n",
      "WARNING:trainer.utils.mpi_adapter:local rank: 0\n",
      "WARNING:trainer.utils.mpi_adapter:master address: 127.0.0.1\n",
      "WARNING:trainer.utils.mpi_adapter:master port: 36873\n",
      "WARNING:trainer.utils.mpi_adapter:----------------\n",
      "INFO:trainer.distributed_trainer:Save config file to data/output_large/test/conf_copy.yaml\n",
      "INFO:trainer.distributed_trainer:Base learning rate: 0.0001\n",
      "INFO:trainer.distributed_trainer:Number of GPUs: 1\n",
      "INFO:trainer.distributed_trainer:Gradient accumulation steps: 1\n",
      "INFO:trainer.default_trainer:Imported base_dir at base_path ../\n",
      "INFO:trainer.default_trainer:Pipeline for training: HDecoderPipeline\n",
      "INFO:trainer.default_trainer:-----------------------------------------------\n",
      "INFO:trainer.default_trainer:Evaluating model ... \n",
      "INFO:base_dir.pipeline.HDecoderPipeline:CDNHOI(\n",
      "  (backbone): D2FocalNet(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (proj): Conv2d(3, 192, kernel_size=(7, 7), stride=(4, 4), padding=(2, 2))\n",
      "      (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "    (layers): ModuleList(\n",
      "      (0): BasicLayer(\n",
      "        (blocks): ModuleList(\n",
      "          (0): FocalModulationBlock(\n",
      "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=192, out_features=389, bias=True)\n",
      "              (h): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (3): Sequential(\n",
      "                  (0): Conv2d(192, 192, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=192, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): FocalModulationBlock(\n",
      "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=192, out_features=389, bias=True)\n",
      "              (h): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (3): Sequential(\n",
      "                  (0): Conv2d(192, 192, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=192, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (downsample): PatchEmbed(\n",
      "          (proj): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicLayer(\n",
      "        (blocks): ModuleList(\n",
      "          (0): FocalModulationBlock(\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=384, out_features=773, bias=True)\n",
      "              (h): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (3): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): FocalModulationBlock(\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=384, out_features=773, bias=True)\n",
      "              (h): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (3): Sequential(\n",
      "                  (0): Conv2d(384, 384, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=384, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (downsample): PatchEmbed(\n",
      "          (proj): Conv2d(384, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (2): BasicLayer(\n",
      "        (blocks): ModuleList(\n",
      "          (0): FocalModulationBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=768, out_features=1541, bias=True)\n",
      "              (h): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (3): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): FocalModulationBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=768, out_features=1541, bias=True)\n",
      "              (h): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (3): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): FocalModulationBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=768, out_features=1541, bias=True)\n",
      "              (h): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (3): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): FocalModulationBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=768, out_features=1541, bias=True)\n",
      "              (h): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (3): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): FocalModulationBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=768, out_features=1541, bias=True)\n",
      "              (h): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (3): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): FocalModulationBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=768, out_features=1541, bias=True)\n",
      "              (h): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (3): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (6): FocalModulationBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=768, out_features=1541, bias=True)\n",
      "              (h): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (3): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (7): FocalModulationBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=768, out_features=1541, bias=True)\n",
      "              (h): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (3): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (8): FocalModulationBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=768, out_features=1541, bias=True)\n",
      "              (h): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (3): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (9): FocalModulationBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=768, out_features=1541, bias=True)\n",
      "              (h): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (3): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (10): FocalModulationBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=768, out_features=1541, bias=True)\n",
      "              (h): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (3): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (11): FocalModulationBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=768, out_features=1541, bias=True)\n",
      "              (h): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (3): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (12): FocalModulationBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=768, out_features=1541, bias=True)\n",
      "              (h): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (3): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (13): FocalModulationBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=768, out_features=1541, bias=True)\n",
      "              (h): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (3): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (14): FocalModulationBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=768, out_features=1541, bias=True)\n",
      "              (h): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (3): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (15): FocalModulationBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=768, out_features=1541, bias=True)\n",
      "              (h): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (3): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (16): FocalModulationBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=768, out_features=1541, bias=True)\n",
      "              (h): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (3): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (17): FocalModulationBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=768, out_features=1541, bias=True)\n",
      "              (h): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (3): Sequential(\n",
      "                  (0): Conv2d(768, 768, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=768, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (downsample): PatchEmbed(\n",
      "          (proj): Conv2d(768, 1536, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (3): BasicLayer(\n",
      "        (blocks): ModuleList(\n",
      "          (0): FocalModulationBlock(\n",
      "            (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=1536, out_features=3077, bias=True)\n",
      "              (h): Conv2d(1536, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(1536, 1536, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1536, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(1536, 1536, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1536, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (3): Sequential(\n",
      "                  (0): Conv2d(1536, 1536, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=1536, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): FocalModulationBlock(\n",
      "            (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "            (modulation): FocalModulation(\n",
      "              (f): Linear(in_features=1536, out_features=3077, bias=True)\n",
      "              (h): Conv2d(1536, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (act): GELU(approximate='none')\n",
      "              (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (focal_layers): ModuleList(\n",
      "                (0): Sequential(\n",
      "                  (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (1): Sequential(\n",
      "                  (0): Conv2d(1536, 1536, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1536, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (2): Sequential(\n",
      "                  (0): Conv2d(1536, 1536, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1536, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "                (3): Sequential(\n",
      "                  (0): Conv2d(1536, 1536, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=1536, bias=False)\n",
      "                  (1): GELU(approximate='none')\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm3): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (hoid_head): CDN(\n",
      "    (encoder): TransformerEncoderHOI(\n",
      "      (adapter_1): Conv2d(\n",
      "        192, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (layer_1): Conv2d(\n",
      "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (adapter_2): Conv2d(\n",
      "        384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (layer_2): Conv2d(\n",
      "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (adapter_3): Conv2d(\n",
      "        768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (layer_3): Conv2d(\n",
      "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (mask_features): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (input_proj): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (transformer): TransformerEncoderOnly(\n",
      "        (encoder): TransformerEncoder(\n",
      "          (layers): ModuleList(\n",
      "            (0): TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (2): TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (3): TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (4): TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (5): TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pe_layer): Positional encoding PositionEmbeddingSine\n",
      "          num_pos_feats: 256\n",
      "          temperature: 10000\n",
      "          normalize: True\n",
      "          scale: 6.283185307179586\n",
      "    )\n",
      "    (hoi_decoder): HDecoder(\n",
      "      (hopd_decoder): TransformerDecoder(\n",
      "        (layers): ModuleList(\n",
      "          (0): TransformerDecoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (multihead_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): TransformerDecoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (multihead_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): TransformerDecoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (multihead_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (3): TransformerDecoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (multihead_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (4): TransformerDecoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (multihead_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (5): TransformerDecoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (multihead_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (interaction_decoder): TransformerDecoder(\n",
      "        (layers): ModuleList(\n",
      "          (0): TransformerDecoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (multihead_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): TransformerDecoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (multihead_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): TransformerDecoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (multihead_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (3): TransformerDecoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (multihead_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (4): TransformerDecoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (multihead_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (5): TransformerDecoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (multihead_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            (dropout3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (query_embed): Embedding(100, 512)\n",
      "    (obj_class_embed): Linear(in_features=512, out_features=82, bias=True)\n",
      "    (verb_class_embed): Linear(in_features=512, out_features=29, bias=True)\n",
      "    (sub_bbox_embed): MLP(\n",
      "      (layers): ModuleList(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (2): Linear(in_features=512, out_features=4, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (obj_bbox_embed): MLP(\n",
      "      (layers): ModuleList(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (2): Linear(in_features=512, out_features=4, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (criterion): SetCriterionHOI(\n",
      "    (matcher): HungarianMatcherHOI()\n",
      "  )\n",
      "  (postprocessors): OfficialPostProcessHOI()\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using use_nms_filter:  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.gamma_1, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.gamma_2, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.f.bias, Model Shape: torch.Size([389]) <-> Ckpt Shape: torch.Size([389])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.f.weight, Model Shape: torch.Size([389, 192]) <-> Ckpt Shape: torch.Size([389, 192])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([192, 1, 3, 3]) <-> Ckpt Shape: torch.Size([192, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([192, 1, 5, 5]) <-> Ckpt Shape: torch.Size([192, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([192, 1, 7, 7]) <-> Ckpt Shape: torch.Size([192, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.focal_layers.3.0.weight, Model Shape: torch.Size([192, 1, 9, 9]) <-> Ckpt Shape: torch.Size([192, 1, 9, 9])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.h.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.h.weight, Model Shape: torch.Size([192, 192, 1, 1]) <-> Ckpt Shape: torch.Size([192, 192, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.modulation.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.0.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.gamma_1, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.gamma_2, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([768, 192]) <-> Ckpt Shape: torch.Size([768, 192])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([192, 768]) <-> Ckpt Shape: torch.Size([192, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.f.bias, Model Shape: torch.Size([389]) <-> Ckpt Shape: torch.Size([389])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.f.weight, Model Shape: torch.Size([389, 192]) <-> Ckpt Shape: torch.Size([389, 192])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([192, 1, 3, 3]) <-> Ckpt Shape: torch.Size([192, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([192, 1, 5, 5]) <-> Ckpt Shape: torch.Size([192, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([192, 1, 7, 7]) <-> Ckpt Shape: torch.Size([192, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.focal_layers.3.0.weight, Model Shape: torch.Size([192, 1, 9, 9]) <-> Ckpt Shape: torch.Size([192, 1, 9, 9])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.h.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.h.weight, Model Shape: torch.Size([192, 192, 1, 1]) <-> Ckpt Shape: torch.Size([192, 192, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.modulation.proj.weight, Model Shape: torch.Size([192, 192]) <-> Ckpt Shape: torch.Size([192, 192])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.norm1.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.norm1.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.norm2.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.0.blocks.1.norm2.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.layers.0.downsample.norm.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.0.downsample.norm.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.0.downsample.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.0.downsample.proj.weight, Model Shape: torch.Size([384, 192, 3, 3]) <-> Ckpt Shape: torch.Size([384, 192, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.gamma_1, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.gamma_2, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.f.bias, Model Shape: torch.Size([773]) <-> Ckpt Shape: torch.Size([773])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.f.weight, Model Shape: torch.Size([773, 384]) <-> Ckpt Shape: torch.Size([773, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([384, 1, 5, 5]) <-> Ckpt Shape: torch.Size([384, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([384, 1, 7, 7]) <-> Ckpt Shape: torch.Size([384, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.focal_layers.3.0.weight, Model Shape: torch.Size([384, 1, 9, 9]) <-> Ckpt Shape: torch.Size([384, 1, 9, 9])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.h.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.h.weight, Model Shape: torch.Size([384, 384, 1, 1]) <-> Ckpt Shape: torch.Size([384, 384, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.modulation.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.0.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.gamma_1, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.gamma_2, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([1536, 384]) <-> Ckpt Shape: torch.Size([1536, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([384, 1536]) <-> Ckpt Shape: torch.Size([384, 1536])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.f.bias, Model Shape: torch.Size([773]) <-> Ckpt Shape: torch.Size([773])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.f.weight, Model Shape: torch.Size([773, 384]) <-> Ckpt Shape: torch.Size([773, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([384, 1, 3, 3]) <-> Ckpt Shape: torch.Size([384, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([384, 1, 5, 5]) <-> Ckpt Shape: torch.Size([384, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([384, 1, 7, 7]) <-> Ckpt Shape: torch.Size([384, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.focal_layers.3.0.weight, Model Shape: torch.Size([384, 1, 9, 9]) <-> Ckpt Shape: torch.Size([384, 1, 9, 9])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.h.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.h.weight, Model Shape: torch.Size([384, 384, 1, 1]) <-> Ckpt Shape: torch.Size([384, 384, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.proj.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.modulation.proj.weight, Model Shape: torch.Size([384, 384]) <-> Ckpt Shape: torch.Size([384, 384])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.norm2.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.1.blocks.1.norm2.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.layers.1.downsample.norm.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.1.downsample.norm.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.1.downsample.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.1.downsample.proj.weight, Model Shape: torch.Size([768, 384, 3, 3]) <-> Ckpt Shape: torch.Size([768, 384, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.gamma_1, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.gamma_2, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.f.bias, Model Shape: torch.Size([1541]) <-> Ckpt Shape: torch.Size([1541])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.f.weight, Model Shape: torch.Size([1541, 768]) <-> Ckpt Shape: torch.Size([1541, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([768, 1, 5, 5]) <-> Ckpt Shape: torch.Size([768, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([768, 1, 7, 7]) <-> Ckpt Shape: torch.Size([768, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.focal_layers.3.0.weight, Model Shape: torch.Size([768, 1, 9, 9]) <-> Ckpt Shape: torch.Size([768, 1, 9, 9])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.h.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.h.weight, Model Shape: torch.Size([768, 768, 1, 1]) <-> Ckpt Shape: torch.Size([768, 768, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.modulation.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.0.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.gamma_1, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.gamma_2, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.f.bias, Model Shape: torch.Size([1541]) <-> Ckpt Shape: torch.Size([1541])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.f.weight, Model Shape: torch.Size([1541, 768]) <-> Ckpt Shape: torch.Size([1541, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([768, 1, 5, 5]) <-> Ckpt Shape: torch.Size([768, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([768, 1, 7, 7]) <-> Ckpt Shape: torch.Size([768, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.focal_layers.3.0.weight, Model Shape: torch.Size([768, 1, 9, 9]) <-> Ckpt Shape: torch.Size([768, 1, 9, 9])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.h.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.h.weight, Model Shape: torch.Size([768, 768, 1, 1]) <-> Ckpt Shape: torch.Size([768, 768, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.modulation.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.1.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.10.gamma_1, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.10.gamma_2, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.10.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.10.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.10.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.10.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.10.modulation.f.bias, Model Shape: torch.Size([1541]) <-> Ckpt Shape: torch.Size([1541])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.10.modulation.f.weight, Model Shape: torch.Size([1541, 768]) <-> Ckpt Shape: torch.Size([1541, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.10.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.10.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([768, 1, 5, 5]) <-> Ckpt Shape: torch.Size([768, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.10.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([768, 1, 7, 7]) <-> Ckpt Shape: torch.Size([768, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.10.modulation.focal_layers.3.0.weight, Model Shape: torch.Size([768, 1, 9, 9]) <-> Ckpt Shape: torch.Size([768, 1, 9, 9])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.10.modulation.h.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.10.modulation.h.weight, Model Shape: torch.Size([768, 768, 1, 1]) <-> Ckpt Shape: torch.Size([768, 768, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.10.modulation.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.10.modulation.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.10.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.10.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.10.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.10.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.11.gamma_1, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.11.gamma_2, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.11.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.11.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.11.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.11.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.11.modulation.f.bias, Model Shape: torch.Size([1541]) <-> Ckpt Shape: torch.Size([1541])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.11.modulation.f.weight, Model Shape: torch.Size([1541, 768]) <-> Ckpt Shape: torch.Size([1541, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.11.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.11.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([768, 1, 5, 5]) <-> Ckpt Shape: torch.Size([768, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.11.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([768, 1, 7, 7]) <-> Ckpt Shape: torch.Size([768, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.11.modulation.focal_layers.3.0.weight, Model Shape: torch.Size([768, 1, 9, 9]) <-> Ckpt Shape: torch.Size([768, 1, 9, 9])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.11.modulation.h.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.11.modulation.h.weight, Model Shape: torch.Size([768, 768, 1, 1]) <-> Ckpt Shape: torch.Size([768, 768, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.11.modulation.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.11.modulation.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.11.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.11.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.11.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.11.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.12.gamma_1, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.12.gamma_2, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.12.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.12.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.12.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.12.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.12.modulation.f.bias, Model Shape: torch.Size([1541]) <-> Ckpt Shape: torch.Size([1541])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.12.modulation.f.weight, Model Shape: torch.Size([1541, 768]) <-> Ckpt Shape: torch.Size([1541, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.12.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.12.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([768, 1, 5, 5]) <-> Ckpt Shape: torch.Size([768, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.12.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([768, 1, 7, 7]) <-> Ckpt Shape: torch.Size([768, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.12.modulation.focal_layers.3.0.weight, Model Shape: torch.Size([768, 1, 9, 9]) <-> Ckpt Shape: torch.Size([768, 1, 9, 9])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.12.modulation.h.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.12.modulation.h.weight, Model Shape: torch.Size([768, 768, 1, 1]) <-> Ckpt Shape: torch.Size([768, 768, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.12.modulation.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.12.modulation.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.12.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.12.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.12.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.12.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.13.gamma_1, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.13.gamma_2, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.13.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.13.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.13.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.13.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.13.modulation.f.bias, Model Shape: torch.Size([1541]) <-> Ckpt Shape: torch.Size([1541])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.13.modulation.f.weight, Model Shape: torch.Size([1541, 768]) <-> Ckpt Shape: torch.Size([1541, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.13.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.13.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([768, 1, 5, 5]) <-> Ckpt Shape: torch.Size([768, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.13.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([768, 1, 7, 7]) <-> Ckpt Shape: torch.Size([768, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.13.modulation.focal_layers.3.0.weight, Model Shape: torch.Size([768, 1, 9, 9]) <-> Ckpt Shape: torch.Size([768, 1, 9, 9])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.13.modulation.h.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.13.modulation.h.weight, Model Shape: torch.Size([768, 768, 1, 1]) <-> Ckpt Shape: torch.Size([768, 768, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.13.modulation.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.13.modulation.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.13.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.13.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.13.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.13.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.14.gamma_1, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.14.gamma_2, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.14.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.14.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.14.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.14.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.14.modulation.f.bias, Model Shape: torch.Size([1541]) <-> Ckpt Shape: torch.Size([1541])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.14.modulation.f.weight, Model Shape: torch.Size([1541, 768]) <-> Ckpt Shape: torch.Size([1541, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.14.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.14.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([768, 1, 5, 5]) <-> Ckpt Shape: torch.Size([768, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.14.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([768, 1, 7, 7]) <-> Ckpt Shape: torch.Size([768, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.14.modulation.focal_layers.3.0.weight, Model Shape: torch.Size([768, 1, 9, 9]) <-> Ckpt Shape: torch.Size([768, 1, 9, 9])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.14.modulation.h.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.14.modulation.h.weight, Model Shape: torch.Size([768, 768, 1, 1]) <-> Ckpt Shape: torch.Size([768, 768, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.14.modulation.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.14.modulation.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.14.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.14.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.14.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.14.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.15.gamma_1, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.15.gamma_2, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.15.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.15.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.15.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.15.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.15.modulation.f.bias, Model Shape: torch.Size([1541]) <-> Ckpt Shape: torch.Size([1541])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.15.modulation.f.weight, Model Shape: torch.Size([1541, 768]) <-> Ckpt Shape: torch.Size([1541, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.15.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.15.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([768, 1, 5, 5]) <-> Ckpt Shape: torch.Size([768, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.15.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([768, 1, 7, 7]) <-> Ckpt Shape: torch.Size([768, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.15.modulation.focal_layers.3.0.weight, Model Shape: torch.Size([768, 1, 9, 9]) <-> Ckpt Shape: torch.Size([768, 1, 9, 9])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.15.modulation.h.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.15.modulation.h.weight, Model Shape: torch.Size([768, 768, 1, 1]) <-> Ckpt Shape: torch.Size([768, 768, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.15.modulation.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.15.modulation.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.15.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.15.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.15.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.15.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.16.gamma_1, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.16.gamma_2, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.16.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.16.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.16.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.16.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.16.modulation.f.bias, Model Shape: torch.Size([1541]) <-> Ckpt Shape: torch.Size([1541])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.16.modulation.f.weight, Model Shape: torch.Size([1541, 768]) <-> Ckpt Shape: torch.Size([1541, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.16.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.16.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([768, 1, 5, 5]) <-> Ckpt Shape: torch.Size([768, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.16.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([768, 1, 7, 7]) <-> Ckpt Shape: torch.Size([768, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.16.modulation.focal_layers.3.0.weight, Model Shape: torch.Size([768, 1, 9, 9]) <-> Ckpt Shape: torch.Size([768, 1, 9, 9])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.16.modulation.h.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.16.modulation.h.weight, Model Shape: torch.Size([768, 768, 1, 1]) <-> Ckpt Shape: torch.Size([768, 768, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.16.modulation.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.16.modulation.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.16.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.16.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.16.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.16.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.17.gamma_1, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.17.gamma_2, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.17.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.17.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.17.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.17.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.17.modulation.f.bias, Model Shape: torch.Size([1541]) <-> Ckpt Shape: torch.Size([1541])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.17.modulation.f.weight, Model Shape: torch.Size([1541, 768]) <-> Ckpt Shape: torch.Size([1541, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.17.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.17.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([768, 1, 5, 5]) <-> Ckpt Shape: torch.Size([768, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.17.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([768, 1, 7, 7]) <-> Ckpt Shape: torch.Size([768, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.17.modulation.focal_layers.3.0.weight, Model Shape: torch.Size([768, 1, 9, 9]) <-> Ckpt Shape: torch.Size([768, 1, 9, 9])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.17.modulation.h.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.17.modulation.h.weight, Model Shape: torch.Size([768, 768, 1, 1]) <-> Ckpt Shape: torch.Size([768, 768, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.17.modulation.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.17.modulation.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.17.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.17.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.17.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.17.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.gamma_1, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.gamma_2, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.f.bias, Model Shape: torch.Size([1541]) <-> Ckpt Shape: torch.Size([1541])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.f.weight, Model Shape: torch.Size([1541, 768]) <-> Ckpt Shape: torch.Size([1541, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([768, 1, 5, 5]) <-> Ckpt Shape: torch.Size([768, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([768, 1, 7, 7]) <-> Ckpt Shape: torch.Size([768, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.focal_layers.3.0.weight, Model Shape: torch.Size([768, 1, 9, 9]) <-> Ckpt Shape: torch.Size([768, 1, 9, 9])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.h.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.h.weight, Model Shape: torch.Size([768, 768, 1, 1]) <-> Ckpt Shape: torch.Size([768, 768, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.modulation.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.2.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.gamma_1, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.gamma_2, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.f.bias, Model Shape: torch.Size([1541]) <-> Ckpt Shape: torch.Size([1541])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.f.weight, Model Shape: torch.Size([1541, 768]) <-> Ckpt Shape: torch.Size([1541, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([768, 1, 5, 5]) <-> Ckpt Shape: torch.Size([768, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([768, 1, 7, 7]) <-> Ckpt Shape: torch.Size([768, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.focal_layers.3.0.weight, Model Shape: torch.Size([768, 1, 9, 9]) <-> Ckpt Shape: torch.Size([768, 1, 9, 9])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.h.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.h.weight, Model Shape: torch.Size([768, 768, 1, 1]) <-> Ckpt Shape: torch.Size([768, 768, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.modulation.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.3.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.gamma_1, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.gamma_2, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.f.bias, Model Shape: torch.Size([1541]) <-> Ckpt Shape: torch.Size([1541])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.f.weight, Model Shape: torch.Size([1541, 768]) <-> Ckpt Shape: torch.Size([1541, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([768, 1, 5, 5]) <-> Ckpt Shape: torch.Size([768, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([768, 1, 7, 7]) <-> Ckpt Shape: torch.Size([768, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.focal_layers.3.0.weight, Model Shape: torch.Size([768, 1, 9, 9]) <-> Ckpt Shape: torch.Size([768, 1, 9, 9])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.h.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.h.weight, Model Shape: torch.Size([768, 768, 1, 1]) <-> Ckpt Shape: torch.Size([768, 768, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.modulation.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.4.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.gamma_1, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.gamma_2, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.f.bias, Model Shape: torch.Size([1541]) <-> Ckpt Shape: torch.Size([1541])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.f.weight, Model Shape: torch.Size([1541, 768]) <-> Ckpt Shape: torch.Size([1541, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([768, 1, 5, 5]) <-> Ckpt Shape: torch.Size([768, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([768, 1, 7, 7]) <-> Ckpt Shape: torch.Size([768, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.focal_layers.3.0.weight, Model Shape: torch.Size([768, 1, 9, 9]) <-> Ckpt Shape: torch.Size([768, 1, 9, 9])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.h.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.h.weight, Model Shape: torch.Size([768, 768, 1, 1]) <-> Ckpt Shape: torch.Size([768, 768, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.modulation.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.5.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.6.gamma_1, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.6.gamma_2, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.6.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.6.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.6.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.6.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.6.modulation.f.bias, Model Shape: torch.Size([1541]) <-> Ckpt Shape: torch.Size([1541])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.6.modulation.f.weight, Model Shape: torch.Size([1541, 768]) <-> Ckpt Shape: torch.Size([1541, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.6.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.6.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([768, 1, 5, 5]) <-> Ckpt Shape: torch.Size([768, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.6.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([768, 1, 7, 7]) <-> Ckpt Shape: torch.Size([768, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.6.modulation.focal_layers.3.0.weight, Model Shape: torch.Size([768, 1, 9, 9]) <-> Ckpt Shape: torch.Size([768, 1, 9, 9])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.6.modulation.h.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.6.modulation.h.weight, Model Shape: torch.Size([768, 768, 1, 1]) <-> Ckpt Shape: torch.Size([768, 768, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.6.modulation.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.6.modulation.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.6.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.6.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.6.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.6.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.7.gamma_1, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.7.gamma_2, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.7.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.7.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.7.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.7.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.7.modulation.f.bias, Model Shape: torch.Size([1541]) <-> Ckpt Shape: torch.Size([1541])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.7.modulation.f.weight, Model Shape: torch.Size([1541, 768]) <-> Ckpt Shape: torch.Size([1541, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.7.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.7.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([768, 1, 5, 5]) <-> Ckpt Shape: torch.Size([768, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.7.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([768, 1, 7, 7]) <-> Ckpt Shape: torch.Size([768, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.7.modulation.focal_layers.3.0.weight, Model Shape: torch.Size([768, 1, 9, 9]) <-> Ckpt Shape: torch.Size([768, 1, 9, 9])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.7.modulation.h.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.7.modulation.h.weight, Model Shape: torch.Size([768, 768, 1, 1]) <-> Ckpt Shape: torch.Size([768, 768, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.7.modulation.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.7.modulation.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.7.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.7.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.7.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.7.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.8.gamma_1, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.8.gamma_2, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.8.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.8.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.8.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.8.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.8.modulation.f.bias, Model Shape: torch.Size([1541]) <-> Ckpt Shape: torch.Size([1541])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.8.modulation.f.weight, Model Shape: torch.Size([1541, 768]) <-> Ckpt Shape: torch.Size([1541, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.8.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.8.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([768, 1, 5, 5]) <-> Ckpt Shape: torch.Size([768, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.8.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([768, 1, 7, 7]) <-> Ckpt Shape: torch.Size([768, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.8.modulation.focal_layers.3.0.weight, Model Shape: torch.Size([768, 1, 9, 9]) <-> Ckpt Shape: torch.Size([768, 1, 9, 9])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.8.modulation.h.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.8.modulation.h.weight, Model Shape: torch.Size([768, 768, 1, 1]) <-> Ckpt Shape: torch.Size([768, 768, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.8.modulation.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.8.modulation.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.8.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.8.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.8.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.8.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.9.gamma_1, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.9.gamma_2, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.9.mlp.fc1.bias, Model Shape: torch.Size([3072]) <-> Ckpt Shape: torch.Size([3072])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.9.mlp.fc1.weight, Model Shape: torch.Size([3072, 768]) <-> Ckpt Shape: torch.Size([3072, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.9.mlp.fc2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.9.mlp.fc2.weight, Model Shape: torch.Size([768, 3072]) <-> Ckpt Shape: torch.Size([768, 3072])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.9.modulation.f.bias, Model Shape: torch.Size([1541]) <-> Ckpt Shape: torch.Size([1541])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.9.modulation.f.weight, Model Shape: torch.Size([1541, 768]) <-> Ckpt Shape: torch.Size([1541, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.9.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([768, 1, 3, 3]) <-> Ckpt Shape: torch.Size([768, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.9.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([768, 1, 5, 5]) <-> Ckpt Shape: torch.Size([768, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.9.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([768, 1, 7, 7]) <-> Ckpt Shape: torch.Size([768, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.9.modulation.focal_layers.3.0.weight, Model Shape: torch.Size([768, 1, 9, 9]) <-> Ckpt Shape: torch.Size([768, 1, 9, 9])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.9.modulation.h.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.9.modulation.h.weight, Model Shape: torch.Size([768, 768, 1, 1]) <-> Ckpt Shape: torch.Size([768, 768, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.9.modulation.proj.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.9.modulation.proj.weight, Model Shape: torch.Size([768, 768]) <-> Ckpt Shape: torch.Size([768, 768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.9.norm1.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.9.norm1.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.9.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.blocks.9.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.layers.2.downsample.norm.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.downsample.norm.weight, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.downsample.proj.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.2.downsample.proj.weight, Model Shape: torch.Size([1536, 768, 3, 3]) <-> Ckpt Shape: torch.Size([1536, 768, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.gamma_1, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.gamma_2, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.mlp.fc1.bias, Model Shape: torch.Size([6144]) <-> Ckpt Shape: torch.Size([6144])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.mlp.fc1.weight, Model Shape: torch.Size([6144, 1536]) <-> Ckpt Shape: torch.Size([6144, 1536])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.mlp.fc2.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.mlp.fc2.weight, Model Shape: torch.Size([1536, 6144]) <-> Ckpt Shape: torch.Size([1536, 6144])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.f.bias, Model Shape: torch.Size([3077]) <-> Ckpt Shape: torch.Size([3077])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.f.weight, Model Shape: torch.Size([3077, 1536]) <-> Ckpt Shape: torch.Size([3077, 1536])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([1536, 1, 3, 3]) <-> Ckpt Shape: torch.Size([1536, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([1536, 1, 5, 5]) <-> Ckpt Shape: torch.Size([1536, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([1536, 1, 7, 7]) <-> Ckpt Shape: torch.Size([1536, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.focal_layers.3.0.weight, Model Shape: torch.Size([1536, 1, 9, 9]) <-> Ckpt Shape: torch.Size([1536, 1, 9, 9])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.h.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.h.weight, Model Shape: torch.Size([1536, 1536, 1, 1]) <-> Ckpt Shape: torch.Size([1536, 1536, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.proj.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.modulation.proj.weight, Model Shape: torch.Size([1536, 1536]) <-> Ckpt Shape: torch.Size([1536, 1536])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.norm1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.norm1.weight, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.norm2.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.0.norm2.weight, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.gamma_1, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.gamma_2, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.mlp.fc1.bias, Model Shape: torch.Size([6144]) <-> Ckpt Shape: torch.Size([6144])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.mlp.fc1.weight, Model Shape: torch.Size([6144, 1536]) <-> Ckpt Shape: torch.Size([6144, 1536])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.mlp.fc2.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.mlp.fc2.weight, Model Shape: torch.Size([1536, 6144]) <-> Ckpt Shape: torch.Size([1536, 6144])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.f.bias, Model Shape: torch.Size([3077]) <-> Ckpt Shape: torch.Size([3077])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.f.weight, Model Shape: torch.Size([3077, 1536]) <-> Ckpt Shape: torch.Size([3077, 1536])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.focal_layers.0.0.weight, Model Shape: torch.Size([1536, 1, 3, 3]) <-> Ckpt Shape: torch.Size([1536, 1, 3, 3])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.focal_layers.1.0.weight, Model Shape: torch.Size([1536, 1, 5, 5]) <-> Ckpt Shape: torch.Size([1536, 1, 5, 5])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.focal_layers.2.0.weight, Model Shape: torch.Size([1536, 1, 7, 7]) <-> Ckpt Shape: torch.Size([1536, 1, 7, 7])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.focal_layers.3.0.weight, Model Shape: torch.Size([1536, 1, 9, 9]) <-> Ckpt Shape: torch.Size([1536, 1, 9, 9])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.h.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.h.weight, Model Shape: torch.Size([1536, 1536, 1, 1]) <-> Ckpt Shape: torch.Size([1536, 1536, 1, 1])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.proj.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.modulation.proj.weight, Model Shape: torch.Size([1536, 1536]) <-> Ckpt Shape: torch.Size([1536, 1536])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.norm1.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.norm1.weight, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.norm2.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.layers.3.blocks.1.norm2.weight, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.norm0.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.norm0.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.norm1.bias, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.norm1.weight, Model Shape: torch.Size([384]) <-> Ckpt Shape: torch.Size([384])\n",
      "INFO:utils.model:Loaded backbone.norm2.bias, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.norm2.weight, Model Shape: torch.Size([768]) <-> Ckpt Shape: torch.Size([768])\n",
      "INFO:utils.model:Loaded backbone.norm3.bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.norm3.weight, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded backbone.patch_embed.norm.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.patch_embed.norm.weight, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.patch_embed.proj.bias, Model Shape: torch.Size([192]) <-> Ckpt Shape: torch.Size([192])\n",
      "INFO:utils.model:Loaded backbone.patch_embed.proj.weight, Model Shape: torch.Size([192, 3, 7, 7]) <-> Ckpt Shape: torch.Size([192, 3, 7, 7])\n",
      "INFO:utils.model:Loaded criterion.empty_weight, Model Shape: torch.Size([82]) <-> Ckpt Shape: torch.Size([82])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_1.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_1.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_1.weight, Model Shape: torch.Size([512, 192, 1, 1]) <-> Ckpt Shape: torch.Size([512, 192, 1, 1])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_2.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_2.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_2.weight, Model Shape: torch.Size([512, 384, 1, 1]) <-> Ckpt Shape: torch.Size([512, 384, 1, 1])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_3.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_3.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.adapter_3.weight, Model Shape: torch.Size([512, 768, 1, 1]) <-> Ckpt Shape: torch.Size([512, 768, 1, 1])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.input_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.input_proj.weight, Model Shape: torch.Size([512, 1536, 1, 1]) <-> Ckpt Shape: torch.Size([512, 1536, 1, 1])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_1.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_1.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_1.weight, Model Shape: torch.Size([512, 512, 3, 3]) <-> Ckpt Shape: torch.Size([512, 512, 3, 3])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_2.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_2.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_2.weight, Model Shape: torch.Size([512, 512, 3, 3]) <-> Ckpt Shape: torch.Size([512, 512, 3, 3])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_3.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_3.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.layer_3.weight, Model Shape: torch.Size([512, 512, 3, 3]) <-> Ckpt Shape: torch.Size([512, 512, 3, 3])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.mask_features.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.mask_features.weight, Model Shape: torch.Size([512, 512, 3, 3]) <-> Ckpt Shape: torch.Size([512, 512, 3, 3])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.0.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.1.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.2.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.3.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.4.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.encoder.transformer.encoder.layers.5.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.multihead_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.multihead_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.multihead_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.multihead_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.norm3.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.norm3.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.0.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.multihead_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.multihead_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.multihead_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.multihead_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.norm3.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.norm3.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.1.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.multihead_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.multihead_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.multihead_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.multihead_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.norm3.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.norm3.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.2.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.3.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.3.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.3.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.3.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.3.multihead_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.3.multihead_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.3.multihead_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.3.multihead_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.3.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.3.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.3.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.3.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.3.norm3.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.3.norm3.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.3.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.3.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.3.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.3.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.4.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.4.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.4.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.4.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.4.multihead_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.4.multihead_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.4.multihead_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.4.multihead_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.4.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.4.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.4.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.4.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.4.norm3.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.4.norm3.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.4.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.4.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.4.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.4.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.5.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.5.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.5.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.5.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.5.multihead_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.5.multihead_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.5.multihead_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.5.multihead_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.5.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.5.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.5.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.5.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.5.norm3.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.5.norm3.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.5.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.5.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.5.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.layers.5.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.hopd_decoder.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.multihead_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.multihead_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.multihead_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.multihead_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.norm3.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.norm3.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.0.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.multihead_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.multihead_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.multihead_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.multihead_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.norm3.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.norm3.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.1.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.multihead_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.multihead_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.multihead_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.multihead_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.norm3.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.norm3.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.2.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.3.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.3.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.3.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.3.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.3.multihead_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.3.multihead_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.3.multihead_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.3.multihead_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.3.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.3.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.3.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.3.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.3.norm3.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.3.norm3.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.3.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.3.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.3.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.3.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.4.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.4.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.4.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.4.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.4.multihead_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.4.multihead_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.4.multihead_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.4.multihead_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.4.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.4.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.4.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.4.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.4.norm3.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.4.norm3.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.4.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.4.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.4.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.4.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.5.linear1.bias, Model Shape: torch.Size([2048]) <-> Ckpt Shape: torch.Size([2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.5.linear1.weight, Model Shape: torch.Size([2048, 512]) <-> Ckpt Shape: torch.Size([2048, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.5.linear2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.5.linear2.weight, Model Shape: torch.Size([512, 2048]) <-> Ckpt Shape: torch.Size([512, 2048])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.5.multihead_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.5.multihead_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.5.multihead_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.5.multihead_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.5.norm1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.5.norm1.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.5.norm2.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.5.norm2.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.5.norm3.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.5.norm3.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.5.self_attn.in_proj_bias, Model Shape: torch.Size([1536]) <-> Ckpt Shape: torch.Size([1536])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.5.self_attn.in_proj_weight, Model Shape: torch.Size([1536, 512]) <-> Ckpt Shape: torch.Size([1536, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.5.self_attn.out_proj.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.layers.5.self_attn.out_proj.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.norm.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.hoi_decoder.interaction_decoder.norm.weight, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.obj_bbox_embed.layers.0.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.obj_bbox_embed.layers.0.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.obj_bbox_embed.layers.1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.obj_bbox_embed.layers.1.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.obj_bbox_embed.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])\n",
      "INFO:utils.model:Loaded hoid_head.obj_bbox_embed.layers.2.weight, Model Shape: torch.Size([4, 512]) <-> Ckpt Shape: torch.Size([4, 512])\n",
      "INFO:utils.model:Loaded hoid_head.obj_class_embed.bias, Model Shape: torch.Size([82]) <-> Ckpt Shape: torch.Size([82])\n",
      "INFO:utils.model:Loaded hoid_head.obj_class_embed.weight, Model Shape: torch.Size([82, 512]) <-> Ckpt Shape: torch.Size([82, 512])\n",
      "INFO:utils.model:Loaded hoid_head.query_embed.weight, Model Shape: torch.Size([100, 512]) <-> Ckpt Shape: torch.Size([100, 512])\n",
      "INFO:utils.model:Loaded hoid_head.sub_bbox_embed.layers.0.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.sub_bbox_embed.layers.0.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.sub_bbox_embed.layers.1.bias, Model Shape: torch.Size([512]) <-> Ckpt Shape: torch.Size([512])\n",
      "INFO:utils.model:Loaded hoid_head.sub_bbox_embed.layers.1.weight, Model Shape: torch.Size([512, 512]) <-> Ckpt Shape: torch.Size([512, 512])\n",
      "INFO:utils.model:Loaded hoid_head.sub_bbox_embed.layers.2.bias, Model Shape: torch.Size([4]) <-> Ckpt Shape: torch.Size([4])\n",
      "INFO:utils.model:Loaded hoid_head.sub_bbox_embed.layers.2.weight, Model Shape: torch.Size([4, 512]) <-> Ckpt Shape: torch.Size([4, 512])\n",
      "INFO:utils.model:Loaded hoid_head.verb_class_embed.bias, Model Shape: torch.Size([29]) <-> Ckpt Shape: torch.Size([29])\n",
      "INFO:utils.model:Loaded hoid_head.verb_class_embed.weight, Model Shape: torch.Size([29, 512]) <-> Ckpt Shape: torch.Size([29, 512])\n",
      "WARNING:utils.model:*UNLOADED* postprocessors.correct_mat, Model Shape: torch.Size([29, 81])\n",
      "INFO:trainer.default_trainer:Evaluation start ...\n",
      "INFO:detectron2.data.common:Serializing 4946 elements to byte tensors and concatenating them all ...\n",
      "INFO:detectron2.data.common:Serialized dataset takes 3.69 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.77s)\n",
      "creating index...\n",
      "index created!\n",
      "loading vcoco annotations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 11/2473. Dataloading: 0.0211 s/iter. Inference: 0.3974 s/iter. Eval: 0.0029 s/iter. Total: 0.4214 s/iter. ETA=0:17:17\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 23/2473. Dataloading: 0.0240 s/iter. Inference: 0.4006 s/iter. Eval: 0.0031 s/iter. Total: 0.4277 s/iter. ETA=0:17:27\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 35/2473. Dataloading: 0.0244 s/iter. Inference: 0.4022 s/iter. Eval: 0.0069 s/iter. Total: 0.4336 s/iter. ETA=0:17:37\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 47/2473. Dataloading: 0.0243 s/iter. Inference: 0.4031 s/iter. Eval: 0.0057 s/iter. Total: 0.4332 s/iter. ETA=0:17:31\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 59/2473. Dataloading: 0.0244 s/iter. Inference: 0.4035 s/iter. Eval: 0.0051 s/iter. Total: 0.4331 s/iter. ETA=0:17:25\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 71/2473. Dataloading: 0.0245 s/iter. Inference: 0.4027 s/iter. Eval: 0.0047 s/iter. Total: 0.4320 s/iter. ETA=0:17:17\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 83/2473. Dataloading: 0.0246 s/iter. Inference: 0.4015 s/iter. Eval: 0.0062 s/iter. Total: 0.4323 s/iter. ETA=0:17:13\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 95/2473. Dataloading: 0.0246 s/iter. Inference: 0.4006 s/iter. Eval: 0.0057 s/iter. Total: 0.4310 s/iter. ETA=0:17:04\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 107/2473. Dataloading: 0.0247 s/iter. Inference: 0.3999 s/iter. Eval: 0.0054 s/iter. Total: 0.4301 s/iter. ETA=0:16:57\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 119/2473. Dataloading: 0.0247 s/iter. Inference: 0.3994 s/iter. Eval: 0.0051 s/iter. Total: 0.4293 s/iter. ETA=0:16:50\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 131/2473. Dataloading: 0.0247 s/iter. Inference: 0.3990 s/iter. Eval: 0.0049 s/iter. Total: 0.4287 s/iter. ETA=0:16:44\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 143/2473. Dataloading: 0.0246 s/iter. Inference: 0.3988 s/iter. Eval: 0.0058 s/iter. Total: 0.4293 s/iter. ETA=0:16:40\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 155/2473. Dataloading: 0.0246 s/iter. Inference: 0.3986 s/iter. Eval: 0.0056 s/iter. Total: 0.4289 s/iter. ETA=0:16:34\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 167/2473. Dataloading: 0.0246 s/iter. Inference: 0.3985 s/iter. Eval: 0.0054 s/iter. Total: 0.4286 s/iter. ETA=0:16:28\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 179/2473. Dataloading: 0.0246 s/iter. Inference: 0.3986 s/iter. Eval: 0.0052 s/iter. Total: 0.4285 s/iter. ETA=0:16:22\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 191/2473. Dataloading: 0.0245 s/iter. Inference: 0.3990 s/iter. Eval: 0.0051 s/iter. Total: 0.4287 s/iter. ETA=0:16:18\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 203/2473. Dataloading: 0.0245 s/iter. Inference: 0.3992 s/iter. Eval: 0.0050 s/iter. Total: 0.4288 s/iter. ETA=0:16:13\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 215/2473. Dataloading: 0.0245 s/iter. Inference: 0.3994 s/iter. Eval: 0.0057 s/iter. Total: 0.4297 s/iter. ETA=0:16:10\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 227/2473. Dataloading: 0.0245 s/iter. Inference: 0.3997 s/iter. Eval: 0.0055 s/iter. Total: 0.4299 s/iter. ETA=0:16:05\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 239/2473. Dataloading: 0.0246 s/iter. Inference: 0.4001 s/iter. Eval: 0.0054 s/iter. Total: 0.4301 s/iter. ETA=0:16:00\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 251/2473. Dataloading: 0.0246 s/iter. Inference: 0.4005 s/iter. Eval: 0.0052 s/iter. Total: 0.4303 s/iter. ETA=0:15:56\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 263/2473. Dataloading: 0.0246 s/iter. Inference: 0.4007 s/iter. Eval: 0.0051 s/iter. Total: 0.4305 s/iter. ETA=0:15:51\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 275/2473. Dataloading: 0.0246 s/iter. Inference: 0.4010 s/iter. Eval: 0.0050 s/iter. Total: 0.4307 s/iter. ETA=0:15:46\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 287/2473. Dataloading: 0.0246 s/iter. Inference: 0.4012 s/iter. Eval: 0.0049 s/iter. Total: 0.4308 s/iter. ETA=0:15:41\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 299/2473. Dataloading: 0.0246 s/iter. Inference: 0.4014 s/iter. Eval: 0.0048 s/iter. Total: 0.4309 s/iter. ETA=0:15:36\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 311/2473. Dataloading: 0.0246 s/iter. Inference: 0.4016 s/iter. Eval: 0.0048 s/iter. Total: 0.4310 s/iter. ETA=0:15:31\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 323/2473. Dataloading: 0.0246 s/iter. Inference: 0.4017 s/iter. Eval: 0.0053 s/iter. Total: 0.4317 s/iter. ETA=0:15:28\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 335/2473. Dataloading: 0.0245 s/iter. Inference: 0.4020 s/iter. Eval: 0.0052 s/iter. Total: 0.4319 s/iter. ETA=0:15:23\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 347/2473. Dataloading: 0.0245 s/iter. Inference: 0.4023 s/iter. Eval: 0.0052 s/iter. Total: 0.4319 s/iter. ETA=0:15:18\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 359/2473. Dataloading: 0.0245 s/iter. Inference: 0.4025 s/iter. Eval: 0.0051 s/iter. Total: 0.4321 s/iter. ETA=0:15:13\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 371/2473. Dataloading: 0.0244 s/iter. Inference: 0.4027 s/iter. Eval: 0.0050 s/iter. Total: 0.4323 s/iter. ETA=0:15:08\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 383/2473. Dataloading: 0.0245 s/iter. Inference: 0.4030 s/iter. Eval: 0.0049 s/iter. Total: 0.4324 s/iter. ETA=0:15:03\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 395/2473. Dataloading: 0.0244 s/iter. Inference: 0.4031 s/iter. Eval: 0.0049 s/iter. Total: 0.4325 s/iter. ETA=0:14:58\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 407/2473. Dataloading: 0.0244 s/iter. Inference: 0.4033 s/iter. Eval: 0.0048 s/iter. Total: 0.4326 s/iter. ETA=0:14:53\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 419/2473. Dataloading: 0.0243 s/iter. Inference: 0.4036 s/iter. Eval: 0.0048 s/iter. Total: 0.4327 s/iter. ETA=0:14:48\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 431/2473. Dataloading: 0.0243 s/iter. Inference: 0.4040 s/iter. Eval: 0.0047 s/iter. Total: 0.4330 s/iter. ETA=0:14:44\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 442/2473. Dataloading: 0.0243 s/iter. Inference: 0.4041 s/iter. Eval: 0.0052 s/iter. Total: 0.4336 s/iter. ETA=0:14:40\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 454/2473. Dataloading: 0.0243 s/iter. Inference: 0.4044 s/iter. Eval: 0.0051 s/iter. Total: 0.4339 s/iter. ETA=0:14:36\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 466/2473. Dataloading: 0.0243 s/iter. Inference: 0.4046 s/iter. Eval: 0.0051 s/iter. Total: 0.4340 s/iter. ETA=0:14:31\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 478/2473. Dataloading: 0.0243 s/iter. Inference: 0.4047 s/iter. Eval: 0.0050 s/iter. Total: 0.4341 s/iter. ETA=0:14:26\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 490/2473. Dataloading: 0.0243 s/iter. Inference: 0.4049 s/iter. Eval: 0.0050 s/iter. Total: 0.4342 s/iter. ETA=0:14:21\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 502/2473. Dataloading: 0.0243 s/iter. Inference: 0.4051 s/iter. Eval: 0.0049 s/iter. Total: 0.4344 s/iter. ETA=0:14:16\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 514/2473. Dataloading: 0.0243 s/iter. Inference: 0.4053 s/iter. Eval: 0.0049 s/iter. Total: 0.4345 s/iter. ETA=0:14:11\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 526/2473. Dataloading: 0.0243 s/iter. Inference: 0.4054 s/iter. Eval: 0.0048 s/iter. Total: 0.4346 s/iter. ETA=0:14:06\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 538/2473. Dataloading: 0.0243 s/iter. Inference: 0.4055 s/iter. Eval: 0.0048 s/iter. Total: 0.4346 s/iter. ETA=0:14:01\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 550/2473. Dataloading: 0.0244 s/iter. Inference: 0.4054 s/iter. Eval: 0.0048 s/iter. Total: 0.4346 s/iter. ETA=0:13:55\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 562/2473. Dataloading: 0.0243 s/iter. Inference: 0.4055 s/iter. Eval: 0.0047 s/iter. Total: 0.4346 s/iter. ETA=0:13:50\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 574/2473. Dataloading: 0.0244 s/iter. Inference: 0.4054 s/iter. Eval: 0.0047 s/iter. Total: 0.4345 s/iter. ETA=0:13:45\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 585/2473. Dataloading: 0.0244 s/iter. Inference: 0.4054 s/iter. Eval: 0.0051 s/iter. Total: 0.4350 s/iter. ETA=0:13:41\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 597/2473. Dataloading: 0.0243 s/iter. Inference: 0.4053 s/iter. Eval: 0.0051 s/iter. Total: 0.4348 s/iter. ETA=0:13:35\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 609/2473. Dataloading: 0.0243 s/iter. Inference: 0.4052 s/iter. Eval: 0.0050 s/iter. Total: 0.4347 s/iter. ETA=0:13:30\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 621/2473. Dataloading: 0.0243 s/iter. Inference: 0.4050 s/iter. Eval: 0.0050 s/iter. Total: 0.4344 s/iter. ETA=0:13:24\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 634/2473. Dataloading: 0.0243 s/iter. Inference: 0.4045 s/iter. Eval: 0.0050 s/iter. Total: 0.4338 s/iter. ETA=0:13:17\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 647/2473. Dataloading: 0.0243 s/iter. Inference: 0.4041 s/iter. Eval: 0.0049 s/iter. Total: 0.4334 s/iter. ETA=0:13:11\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 660/2473. Dataloading: 0.0243 s/iter. Inference: 0.4034 s/iter. Eval: 0.0049 s/iter. Total: 0.4326 s/iter. ETA=0:13:04\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 673/2473. Dataloading: 0.0243 s/iter. Inference: 0.4027 s/iter. Eval: 0.0048 s/iter. Total: 0.4319 s/iter. ETA=0:12:57\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 686/2473. Dataloading: 0.0243 s/iter. Inference: 0.4023 s/iter. Eval: 0.0048 s/iter. Total: 0.4315 s/iter. ETA=0:12:51\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 698/2473. Dataloading: 0.0243 s/iter. Inference: 0.4021 s/iter. Eval: 0.0048 s/iter. Total: 0.4313 s/iter. ETA=0:12:45\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 711/2473. Dataloading: 0.0243 s/iter. Inference: 0.4018 s/iter. Eval: 0.0047 s/iter. Total: 0.4309 s/iter. ETA=0:12:39\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 723/2473. Dataloading: 0.0243 s/iter. Inference: 0.4018 s/iter. Eval: 0.0047 s/iter. Total: 0.4309 s/iter. ETA=0:12:34\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 736/2473. Dataloading: 0.0243 s/iter. Inference: 0.4013 s/iter. Eval: 0.0047 s/iter. Total: 0.4304 s/iter. ETA=0:12:27\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 749/2473. Dataloading: 0.0243 s/iter. Inference: 0.4009 s/iter. Eval: 0.0046 s/iter. Total: 0.4299 s/iter. ETA=0:12:21\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 762/2473. Dataloading: 0.0243 s/iter. Inference: 0.4005 s/iter. Eval: 0.0046 s/iter. Total: 0.4295 s/iter. ETA=0:12:14\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 774/2473. Dataloading: 0.0243 s/iter. Inference: 0.4005 s/iter. Eval: 0.0046 s/iter. Total: 0.4295 s/iter. ETA=0:12:09\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 787/2473. Dataloading: 0.0243 s/iter. Inference: 0.4001 s/iter. Eval: 0.0045 s/iter. Total: 0.4291 s/iter. ETA=0:12:03\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 800/2473. Dataloading: 0.0243 s/iter. Inference: 0.3999 s/iter. Eval: 0.0045 s/iter. Total: 0.4288 s/iter. ETA=0:11:57\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 813/2473. Dataloading: 0.0243 s/iter. Inference: 0.3997 s/iter. Eval: 0.0045 s/iter. Total: 0.4286 s/iter. ETA=0:11:51\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 826/2473. Dataloading: 0.0243 s/iter. Inference: 0.3994 s/iter. Eval: 0.0045 s/iter. Total: 0.4283 s/iter. ETA=0:11:45\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 838/2473. Dataloading: 0.0243 s/iter. Inference: 0.3993 s/iter. Eval: 0.0044 s/iter. Total: 0.4282 s/iter. ETA=0:11:40\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 851/2473. Dataloading: 0.0243 s/iter. Inference: 0.3991 s/iter. Eval: 0.0044 s/iter. Total: 0.4279 s/iter. ETA=0:11:34\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 864/2473. Dataloading: 0.0243 s/iter. Inference: 0.3988 s/iter. Eval: 0.0044 s/iter. Total: 0.4276 s/iter. ETA=0:11:27\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 876/2473. Dataloading: 0.0243 s/iter. Inference: 0.3989 s/iter. Eval: 0.0044 s/iter. Total: 0.4277 s/iter. ETA=0:11:22\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 888/2473. Dataloading: 0.0244 s/iter. Inference: 0.3990 s/iter. Eval: 0.0044 s/iter. Total: 0.4278 s/iter. ETA=0:11:18\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 900/2473. Dataloading: 0.0243 s/iter. Inference: 0.3990 s/iter. Eval: 0.0043 s/iter. Total: 0.4278 s/iter. ETA=0:11:12\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 913/2473. Dataloading: 0.0244 s/iter. Inference: 0.3987 s/iter. Eval: 0.0043 s/iter. Total: 0.4274 s/iter. ETA=0:11:06\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 926/2473. Dataloading: 0.0244 s/iter. Inference: 0.3985 s/iter. Eval: 0.0043 s/iter. Total: 0.4272 s/iter. ETA=0:11:00\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 938/2473. Dataloading: 0.0244 s/iter. Inference: 0.3983 s/iter. Eval: 0.0043 s/iter. Total: 0.4271 s/iter. ETA=0:10:55\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 951/2473. Dataloading: 0.0244 s/iter. Inference: 0.3982 s/iter. Eval: 0.0043 s/iter. Total: 0.4269 s/iter. ETA=0:10:49\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 963/2473. Dataloading: 0.0244 s/iter. Inference: 0.3981 s/iter. Eval: 0.0043 s/iter. Total: 0.4268 s/iter. ETA=0:10:44\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 976/2473. Dataloading: 0.0244 s/iter. Inference: 0.3979 s/iter. Eval: 0.0042 s/iter. Total: 0.4266 s/iter. ETA=0:10:38\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 989/2473. Dataloading: 0.0244 s/iter. Inference: 0.3976 s/iter. Eval: 0.0042 s/iter. Total: 0.4262 s/iter. ETA=0:10:32\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1001/2473. Dataloading: 0.0243 s/iter. Inference: 0.3973 s/iter. Eval: 0.0046 s/iter. Total: 0.4263 s/iter. ETA=0:10:27\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1014/2473. Dataloading: 0.0243 s/iter. Inference: 0.3971 s/iter. Eval: 0.0046 s/iter. Total: 0.4260 s/iter. ETA=0:10:21\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1027/2473. Dataloading: 0.0243 s/iter. Inference: 0.3969 s/iter. Eval: 0.0045 s/iter. Total: 0.4259 s/iter. ETA=0:10:15\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1039/2473. Dataloading: 0.0243 s/iter. Inference: 0.3970 s/iter. Eval: 0.0045 s/iter. Total: 0.4259 s/iter. ETA=0:10:10\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1051/2473. Dataloading: 0.0243 s/iter. Inference: 0.3971 s/iter. Eval: 0.0045 s/iter. Total: 0.4260 s/iter. ETA=0:10:05\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1063/2473. Dataloading: 0.0243 s/iter. Inference: 0.3973 s/iter. Eval: 0.0045 s/iter. Total: 0.4262 s/iter. ETA=0:10:00\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1075/2473. Dataloading: 0.0244 s/iter. Inference: 0.3974 s/iter. Eval: 0.0045 s/iter. Total: 0.4263 s/iter. ETA=0:09:55\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1087/2473. Dataloading: 0.0244 s/iter. Inference: 0.3975 s/iter. Eval: 0.0045 s/iter. Total: 0.4264 s/iter. ETA=0:09:50\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1099/2473. Dataloading: 0.0244 s/iter. Inference: 0.3975 s/iter. Eval: 0.0044 s/iter. Total: 0.4264 s/iter. ETA=0:09:45\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1111/2473. Dataloading: 0.0244 s/iter. Inference: 0.3976 s/iter. Eval: 0.0044 s/iter. Total: 0.4264 s/iter. ETA=0:09:40\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1123/2473. Dataloading: 0.0244 s/iter. Inference: 0.3976 s/iter. Eval: 0.0044 s/iter. Total: 0.4265 s/iter. ETA=0:09:35\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1135/2473. Dataloading: 0.0244 s/iter. Inference: 0.3977 s/iter. Eval: 0.0044 s/iter. Total: 0.4265 s/iter. ETA=0:09:30\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1147/2473. Dataloading: 0.0244 s/iter. Inference: 0.3978 s/iter. Eval: 0.0044 s/iter. Total: 0.4266 s/iter. ETA=0:09:25\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1159/2473. Dataloading: 0.0244 s/iter. Inference: 0.3979 s/iter. Eval: 0.0044 s/iter. Total: 0.4267 s/iter. ETA=0:09:20\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1171/2473. Dataloading: 0.0244 s/iter. Inference: 0.3979 s/iter. Eval: 0.0043 s/iter. Total: 0.4268 s/iter. ETA=0:09:15\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1183/2473. Dataloading: 0.0244 s/iter. Inference: 0.3980 s/iter. Eval: 0.0043 s/iter. Total: 0.4268 s/iter. ETA=0:09:10\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1195/2473. Dataloading: 0.0244 s/iter. Inference: 0.3980 s/iter. Eval: 0.0043 s/iter. Total: 0.4268 s/iter. ETA=0:09:05\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1207/2473. Dataloading: 0.0244 s/iter. Inference: 0.3981 s/iter. Eval: 0.0043 s/iter. Total: 0.4269 s/iter. ETA=0:09:00\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1219/2473. Dataloading: 0.0244 s/iter. Inference: 0.3981 s/iter. Eval: 0.0043 s/iter. Total: 0.4269 s/iter. ETA=0:08:55\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1231/2473. Dataloading: 0.0244 s/iter. Inference: 0.3981 s/iter. Eval: 0.0043 s/iter. Total: 0.4269 s/iter. ETA=0:08:50\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1243/2473. Dataloading: 0.0244 s/iter. Inference: 0.3981 s/iter. Eval: 0.0043 s/iter. Total: 0.4268 s/iter. ETA=0:08:44\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1254/2473. Dataloading: 0.0244 s/iter. Inference: 0.3985 s/iter. Eval: 0.0043 s/iter. Total: 0.4273 s/iter. ETA=0:08:40\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1265/2473. Dataloading: 0.0244 s/iter. Inference: 0.3989 s/iter. Eval: 0.0042 s/iter. Total: 0.4276 s/iter. ETA=0:08:36\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1276/2473. Dataloading: 0.0244 s/iter. Inference: 0.3993 s/iter. Eval: 0.0042 s/iter. Total: 0.4280 s/iter. ETA=0:08:32\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1286/2473. Dataloading: 0.0244 s/iter. Inference: 0.3995 s/iter. Eval: 0.0046 s/iter. Total: 0.4286 s/iter. ETA=0:08:28\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1297/2473. Dataloading: 0.0244 s/iter. Inference: 0.4001 s/iter. Eval: 0.0046 s/iter. Total: 0.4292 s/iter. ETA=0:08:24\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1309/2473. Dataloading: 0.0244 s/iter. Inference: 0.4003 s/iter. Eval: 0.0046 s/iter. Total: 0.4293 s/iter. ETA=0:08:19\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1321/2473. Dataloading: 0.0244 s/iter. Inference: 0.4005 s/iter. Eval: 0.0046 s/iter. Total: 0.4295 s/iter. ETA=0:08:14\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1334/2473. Dataloading: 0.0243 s/iter. Inference: 0.4004 s/iter. Eval: 0.0046 s/iter. Total: 0.4293 s/iter. ETA=0:08:08\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1346/2473. Dataloading: 0.0243 s/iter. Inference: 0.4004 s/iter. Eval: 0.0045 s/iter. Total: 0.4293 s/iter. ETA=0:08:03\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1358/2473. Dataloading: 0.0243 s/iter. Inference: 0.4005 s/iter. Eval: 0.0045 s/iter. Total: 0.4294 s/iter. ETA=0:07:58\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1370/2473. Dataloading: 0.0244 s/iter. Inference: 0.4005 s/iter. Eval: 0.0045 s/iter. Total: 0.4295 s/iter. ETA=0:07:53\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1382/2473. Dataloading: 0.0243 s/iter. Inference: 0.4007 s/iter. Eval: 0.0045 s/iter. Total: 0.4296 s/iter. ETA=0:07:48\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1394/2473. Dataloading: 0.0243 s/iter. Inference: 0.4008 s/iter. Eval: 0.0045 s/iter. Total: 0.4297 s/iter. ETA=0:07:43\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1406/2473. Dataloading: 0.0243 s/iter. Inference: 0.4008 s/iter. Eval: 0.0045 s/iter. Total: 0.4297 s/iter. ETA=0:07:38\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1418/2473. Dataloading: 0.0244 s/iter. Inference: 0.4009 s/iter. Eval: 0.0045 s/iter. Total: 0.4298 s/iter. ETA=0:07:33\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1430/2473. Dataloading: 0.0244 s/iter. Inference: 0.4010 s/iter. Eval: 0.0044 s/iter. Total: 0.4299 s/iter. ETA=0:07:28\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1442/2473. Dataloading: 0.0244 s/iter. Inference: 0.4010 s/iter. Eval: 0.0044 s/iter. Total: 0.4299 s/iter. ETA=0:07:23\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1454/2473. Dataloading: 0.0244 s/iter. Inference: 0.4011 s/iter. Eval: 0.0044 s/iter. Total: 0.4300 s/iter. ETA=0:07:18\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1466/2473. Dataloading: 0.0244 s/iter. Inference: 0.4012 s/iter. Eval: 0.0044 s/iter. Total: 0.4300 s/iter. ETA=0:07:13\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1478/2473. Dataloading: 0.0244 s/iter. Inference: 0.4012 s/iter. Eval: 0.0044 s/iter. Total: 0.4301 s/iter. ETA=0:07:07\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1490/2473. Dataloading: 0.0244 s/iter. Inference: 0.4013 s/iter. Eval: 0.0044 s/iter. Total: 0.4301 s/iter. ETA=0:07:02\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1502/2473. Dataloading: 0.0244 s/iter. Inference: 0.4013 s/iter. Eval: 0.0044 s/iter. Total: 0.4301 s/iter. ETA=0:06:57\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1514/2473. Dataloading: 0.0244 s/iter. Inference: 0.4014 s/iter. Eval: 0.0044 s/iter. Total: 0.4302 s/iter. ETA=0:06:52\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1526/2473. Dataloading: 0.0244 s/iter. Inference: 0.4014 s/iter. Eval: 0.0043 s/iter. Total: 0.4302 s/iter. ETA=0:06:47\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1538/2473. Dataloading: 0.0244 s/iter. Inference: 0.4014 s/iter. Eval: 0.0043 s/iter. Total: 0.4302 s/iter. ETA=0:06:42\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1550/2473. Dataloading: 0.0244 s/iter. Inference: 0.4014 s/iter. Eval: 0.0043 s/iter. Total: 0.4302 s/iter. ETA=0:06:37\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1562/2473. Dataloading: 0.0244 s/iter. Inference: 0.4014 s/iter. Eval: 0.0043 s/iter. Total: 0.4302 s/iter. ETA=0:06:31\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1574/2473. Dataloading: 0.0244 s/iter. Inference: 0.4015 s/iter. Eval: 0.0043 s/iter. Total: 0.4302 s/iter. ETA=0:06:26\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1586/2473. Dataloading: 0.0244 s/iter. Inference: 0.4015 s/iter. Eval: 0.0043 s/iter. Total: 0.4302 s/iter. ETA=0:06:21\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1598/2473. Dataloading: 0.0244 s/iter. Inference: 0.4015 s/iter. Eval: 0.0043 s/iter. Total: 0.4302 s/iter. ETA=0:06:16\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1610/2473. Dataloading: 0.0244 s/iter. Inference: 0.4015 s/iter. Eval: 0.0043 s/iter. Total: 0.4302 s/iter. ETA=0:06:11\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1622/2473. Dataloading: 0.0244 s/iter. Inference: 0.4016 s/iter. Eval: 0.0043 s/iter. Total: 0.4303 s/iter. ETA=0:06:06\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1634/2473. Dataloading: 0.0244 s/iter. Inference: 0.4016 s/iter. Eval: 0.0042 s/iter. Total: 0.4303 s/iter. ETA=0:06:01\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1643/2473. Dataloading: 0.0244 s/iter. Inference: 0.4021 s/iter. Eval: 0.0046 s/iter. Total: 0.4312 s/iter. ETA=0:05:57\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1653/2473. Dataloading: 0.0244 s/iter. Inference: 0.4027 s/iter. Eval: 0.0046 s/iter. Total: 0.4317 s/iter. ETA=0:05:54\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1663/2473. Dataloading: 0.0244 s/iter. Inference: 0.4031 s/iter. Eval: 0.0046 s/iter. Total: 0.4322 s/iter. ETA=0:05:50\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1674/2473. Dataloading: 0.0244 s/iter. Inference: 0.4034 s/iter. Eval: 0.0046 s/iter. Total: 0.4324 s/iter. ETA=0:05:45\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1686/2473. Dataloading: 0.0244 s/iter. Inference: 0.4035 s/iter. Eval: 0.0046 s/iter. Total: 0.4325 s/iter. ETA=0:05:40\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1698/2473. Dataloading: 0.0244 s/iter. Inference: 0.4036 s/iter. Eval: 0.0046 s/iter. Total: 0.4326 s/iter. ETA=0:05:35\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1710/2473. Dataloading: 0.0244 s/iter. Inference: 0.4036 s/iter. Eval: 0.0046 s/iter. Total: 0.4326 s/iter. ETA=0:05:30\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1722/2473. Dataloading: 0.0244 s/iter. Inference: 0.4036 s/iter. Eval: 0.0046 s/iter. Total: 0.4326 s/iter. ETA=0:05:24\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1734/2473. Dataloading: 0.0244 s/iter. Inference: 0.4036 s/iter. Eval: 0.0046 s/iter. Total: 0.4325 s/iter. ETA=0:05:19\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1746/2473. Dataloading: 0.0244 s/iter. Inference: 0.4035 s/iter. Eval: 0.0045 s/iter. Total: 0.4325 s/iter. ETA=0:05:14\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1757/2473. Dataloading: 0.0244 s/iter. Inference: 0.4038 s/iter. Eval: 0.0045 s/iter. Total: 0.4328 s/iter. ETA=0:05:09\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1767/2473. Dataloading: 0.0243 s/iter. Inference: 0.4043 s/iter. Eval: 0.0045 s/iter. Total: 0.4333 s/iter. ETA=0:05:05\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1778/2473. Dataloading: 0.0243 s/iter. Inference: 0.4047 s/iter. Eval: 0.0045 s/iter. Total: 0.4336 s/iter. ETA=0:05:01\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1789/2473. Dataloading: 0.0244 s/iter. Inference: 0.4050 s/iter. Eval: 0.0045 s/iter. Total: 0.4339 s/iter. ETA=0:04:56\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1799/2473. Dataloading: 0.0244 s/iter. Inference: 0.4054 s/iter. Eval: 0.0045 s/iter. Total: 0.4343 s/iter. ETA=0:04:52\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1810/2473. Dataloading: 0.0244 s/iter. Inference: 0.4056 s/iter. Eval: 0.0045 s/iter. Total: 0.4345 s/iter. ETA=0:04:48\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1822/2473. Dataloading: 0.0243 s/iter. Inference: 0.4056 s/iter. Eval: 0.0045 s/iter. Total: 0.4345 s/iter. ETA=0:04:42\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1832/2473. Dataloading: 0.0244 s/iter. Inference: 0.4060 s/iter. Eval: 0.0045 s/iter. Total: 0.4348 s/iter. ETA=0:04:38\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1843/2473. Dataloading: 0.0244 s/iter. Inference: 0.4062 s/iter. Eval: 0.0045 s/iter. Total: 0.4350 s/iter. ETA=0:04:34\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1856/2473. Dataloading: 0.0244 s/iter. Inference: 0.4060 s/iter. Eval: 0.0044 s/iter. Total: 0.4349 s/iter. ETA=0:04:28\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1869/2473. Dataloading: 0.0244 s/iter. Inference: 0.4058 s/iter. Eval: 0.0044 s/iter. Total: 0.4347 s/iter. ETA=0:04:22\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1882/2473. Dataloading: 0.0244 s/iter. Inference: 0.4056 s/iter. Eval: 0.0044 s/iter. Total: 0.4344 s/iter. ETA=0:04:16\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1895/2473. Dataloading: 0.0244 s/iter. Inference: 0.4054 s/iter. Eval: 0.0044 s/iter. Total: 0.4343 s/iter. ETA=0:04:10\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1908/2473. Dataloading: 0.0244 s/iter. Inference: 0.4052 s/iter. Eval: 0.0044 s/iter. Total: 0.4340 s/iter. ETA=0:04:05\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1921/2473. Dataloading: 0.0244 s/iter. Inference: 0.4050 s/iter. Eval: 0.0044 s/iter. Total: 0.4338 s/iter. ETA=0:03:59\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1934/2473. Dataloading: 0.0244 s/iter. Inference: 0.4048 s/iter. Eval: 0.0044 s/iter. Total: 0.4336 s/iter. ETA=0:03:53\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1947/2473. Dataloading: 0.0244 s/iter. Inference: 0.4047 s/iter. Eval: 0.0044 s/iter. Total: 0.4334 s/iter. ETA=0:03:47\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1960/2473. Dataloading: 0.0244 s/iter. Inference: 0.4045 s/iter. Eval: 0.0044 s/iter. Total: 0.4333 s/iter. ETA=0:03:42\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1973/2473. Dataloading: 0.0243 s/iter. Inference: 0.4044 s/iter. Eval: 0.0043 s/iter. Total: 0.4332 s/iter. ETA=0:03:36\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1986/2473. Dataloading: 0.0244 s/iter. Inference: 0.4043 s/iter. Eval: 0.0043 s/iter. Total: 0.4330 s/iter. ETA=0:03:30\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 1999/2473. Dataloading: 0.0244 s/iter. Inference: 0.4041 s/iter. Eval: 0.0043 s/iter. Total: 0.4328 s/iter. ETA=0:03:25\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2011/2473. Dataloading: 0.0244 s/iter. Inference: 0.4040 s/iter. Eval: 0.0043 s/iter. Total: 0.4328 s/iter. ETA=0:03:19\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2024/2473. Dataloading: 0.0244 s/iter. Inference: 0.4039 s/iter. Eval: 0.0043 s/iter. Total: 0.4326 s/iter. ETA=0:03:14\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2037/2473. Dataloading: 0.0244 s/iter. Inference: 0.4037 s/iter. Eval: 0.0043 s/iter. Total: 0.4324 s/iter. ETA=0:03:08\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2050/2473. Dataloading: 0.0243 s/iter. Inference: 0.4035 s/iter. Eval: 0.0043 s/iter. Total: 0.4322 s/iter. ETA=0:03:02\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2063/2473. Dataloading: 0.0243 s/iter. Inference: 0.4033 s/iter. Eval: 0.0043 s/iter. Total: 0.4320 s/iter. ETA=0:02:57\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2076/2473. Dataloading: 0.0243 s/iter. Inference: 0.4031 s/iter. Eval: 0.0043 s/iter. Total: 0.4318 s/iter. ETA=0:02:51\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2089/2473. Dataloading: 0.0243 s/iter. Inference: 0.4029 s/iter. Eval: 0.0043 s/iter. Total: 0.4316 s/iter. ETA=0:02:45\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2100/2473. Dataloading: 0.0244 s/iter. Inference: 0.4028 s/iter. Eval: 0.0046 s/iter. Total: 0.4318 s/iter. ETA=0:02:41\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2113/2473. Dataloading: 0.0243 s/iter. Inference: 0.4027 s/iter. Eval: 0.0046 s/iter. Total: 0.4317 s/iter. ETA=0:02:35\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2126/2473. Dataloading: 0.0243 s/iter. Inference: 0.4025 s/iter. Eval: 0.0046 s/iter. Total: 0.4315 s/iter. ETA=0:02:29\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2139/2473. Dataloading: 0.0243 s/iter. Inference: 0.4024 s/iter. Eval: 0.0046 s/iter. Total: 0.4314 s/iter. ETA=0:02:24\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2151/2473. Dataloading: 0.0243 s/iter. Inference: 0.4024 s/iter. Eval: 0.0045 s/iter. Total: 0.4313 s/iter. ETA=0:02:18\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2163/2473. Dataloading: 0.0243 s/iter. Inference: 0.4023 s/iter. Eval: 0.0045 s/iter. Total: 0.4312 s/iter. ETA=0:02:13\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2176/2473. Dataloading: 0.0243 s/iter. Inference: 0.4022 s/iter. Eval: 0.0045 s/iter. Total: 0.4312 s/iter. ETA=0:02:08\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2189/2473. Dataloading: 0.0243 s/iter. Inference: 0.4021 s/iter. Eval: 0.0045 s/iter. Total: 0.4310 s/iter. ETA=0:02:02\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2201/2473. Dataloading: 0.0243 s/iter. Inference: 0.4020 s/iter. Eval: 0.0045 s/iter. Total: 0.4309 s/iter. ETA=0:01:57\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2214/2473. Dataloading: 0.0243 s/iter. Inference: 0.4019 s/iter. Eval: 0.0045 s/iter. Total: 0.4308 s/iter. ETA=0:01:51\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2226/2473. Dataloading: 0.0243 s/iter. Inference: 0.4019 s/iter. Eval: 0.0045 s/iter. Total: 0.4308 s/iter. ETA=0:01:46\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2239/2473. Dataloading: 0.0243 s/iter. Inference: 0.4018 s/iter. Eval: 0.0045 s/iter. Total: 0.4307 s/iter. ETA=0:01:40\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2252/2473. Dataloading: 0.0243 s/iter. Inference: 0.4016 s/iter. Eval: 0.0045 s/iter. Total: 0.4305 s/iter. ETA=0:01:35\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2265/2473. Dataloading: 0.0243 s/iter. Inference: 0.4015 s/iter. Eval: 0.0045 s/iter. Total: 0.4304 s/iter. ETA=0:01:29\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2278/2473. Dataloading: 0.0243 s/iter. Inference: 0.4014 s/iter. Eval: 0.0044 s/iter. Total: 0.4303 s/iter. ETA=0:01:23\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2290/2473. Dataloading: 0.0243 s/iter. Inference: 0.4014 s/iter. Eval: 0.0044 s/iter. Total: 0.4302 s/iter. ETA=0:01:18\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2303/2473. Dataloading: 0.0243 s/iter. Inference: 0.4013 s/iter. Eval: 0.0044 s/iter. Total: 0.4301 s/iter. ETA=0:01:13\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2316/2473. Dataloading: 0.0243 s/iter. Inference: 0.4011 s/iter. Eval: 0.0044 s/iter. Total: 0.4300 s/iter. ETA=0:01:07\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2329/2473. Dataloading: 0.0243 s/iter. Inference: 0.4010 s/iter. Eval: 0.0044 s/iter. Total: 0.4298 s/iter. ETA=0:01:01\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2342/2473. Dataloading: 0.0243 s/iter. Inference: 0.4009 s/iter. Eval: 0.0044 s/iter. Total: 0.4297 s/iter. ETA=0:00:56\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2355/2473. Dataloading: 0.0243 s/iter. Inference: 0.4008 s/iter. Eval: 0.0044 s/iter. Total: 0.4296 s/iter. ETA=0:00:50\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2368/2473. Dataloading: 0.0243 s/iter. Inference: 0.4007 s/iter. Eval: 0.0044 s/iter. Total: 0.4295 s/iter. ETA=0:00:45\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2381/2473. Dataloading: 0.0243 s/iter. Inference: 0.4006 s/iter. Eval: 0.0044 s/iter. Total: 0.4294 s/iter. ETA=0:00:39\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2394/2473. Dataloading: 0.0243 s/iter. Inference: 0.4006 s/iter. Eval: 0.0044 s/iter. Total: 0.4294 s/iter. ETA=0:00:33\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2407/2473. Dataloading: 0.0243 s/iter. Inference: 0.4004 s/iter. Eval: 0.0044 s/iter. Total: 0.4292 s/iter. ETA=0:00:28\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2420/2473. Dataloading: 0.0243 s/iter. Inference: 0.4003 s/iter. Eval: 0.0044 s/iter. Total: 0.4291 s/iter. ETA=0:00:22\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2433/2473. Dataloading: 0.0243 s/iter. Inference: 0.4002 s/iter. Eval: 0.0043 s/iter. Total: 0.4290 s/iter. ETA=0:00:17\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2446/2473. Dataloading: 0.0243 s/iter. Inference: 0.4002 s/iter. Eval: 0.0043 s/iter. Total: 0.4289 s/iter. ETA=0:00:11\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2459/2473. Dataloading: 0.0243 s/iter. Inference: 0.4001 s/iter. Eval: 0.0043 s/iter. Total: 0.4288 s/iter. ETA=0:00:06\n",
      "INFO:base_dir.pipeline.HDecoderPipeline:Inference done 2472/2473. Dataloading: 0.0243 s/iter. Inference: 0.4000 s/iter. Eval: 0.0043 s/iter. Total: 0.4287 s/iter. ETA=0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate scenario_1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:trainer.default_trainer:{'vcoco_val/hoi': {'AP_scenario_1': 0.56191754}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Reporting Role AP (%)------------------\n",
      "               hold-obj: AP = 49.56 (#pos = 3608)\n",
      "              sit-instr: AP = 50.25 (#pos = 1916)\n",
      "             ride-instr: AP = 65.52 (#pos = 556)\n",
      "               look-obj: AP = 42.24 (#pos = 3347)\n",
      "              hit-instr: AP = 75.96 (#pos = 349)\n",
      "                hit-obj: AP = 42.40 (#pos = 349)\n",
      "                eat-obj: AP = 61.55 (#pos = 521)\n",
      "              eat-instr: AP = 75.18 (#pos = 521)\n",
      "             jump-instr: AP = 79.07 (#pos = 635)\n",
      "              lay-instr: AP = 59.75 (#pos = 387)\n",
      "    talk_on_phone-instr: AP = 39.64 (#pos = 285)\n",
      "              carry-obj: AP = 39.98 (#pos = 472)\n",
      "              throw-obj: AP = 40.72 (#pos = 244)\n",
      "              catch-obj: AP = 51.14 (#pos = 246)\n",
      "              cut-instr: AP = 42.50 (#pos = 269)\n",
      "                cut-obj: AP = 63.98 (#pos = 269)\n",
      " work_on_computer-instr: AP = 66.57 (#pos = 410)\n",
      "              ski-instr: AP = 41.29 (#pos = 424)\n",
      "             surf-instr: AP = 72.78 (#pos = 486)\n",
      "       skateboard-instr: AP = 77.47 (#pos = 417)\n",
      "            drink-instr: AP = 57.87 (#pos = 82)\n",
      "               kick-obj: AP = 81.38 (#pos = 180)\n",
      "            point-instr: AP = 1.51 (#pos = 31)\n",
      "               read-obj: AP = 52.96 (#pos = 111)\n",
      "        snowboard-instr: AP = 73.54 (#pos = 277)\n",
      "Average Role [scenario_1] AP = 56.19\n",
      "---------------------------------------------\n",
      "Average Role [scenario_1] AP = 58.47, omitting the action \"point\"\n",
      "---------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'vcoco_val/hoi': {'AP_scenario_1': 0.56191754}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from trainer import HDecoder_Trainer as Trainer\n",
    "if cmdline_args.user_dir:\n",
    "    absolute_user_dir = os.path.abspath(cmdline_args.user_dir)\n",
    "    opt['base_path'] = absolute_user_dir\n",
    "trainer = Trainer(opt)\n",
    "trainer.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_X_Decoder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
